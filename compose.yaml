# NOTE: deploy
# docker node update --label-add ollama=true `docker node inspect self --format "{{ .ID }}"`

services:
  ollama:
    image: ghcr.io/zerocluster/ollama
    depends_on: []
    init: true
    stop_grace_period: 5m

    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
        constraints:
          - "node.labels.ollama == true"
      # resources:
      #   reservations:
      #     generic_resources:
      #       - discrete_resource_spec:
      #           kind: NVIDIA-GPU
      #           value: 0

    command: run

    # secrets:
    #   - { source: ollama_env.yaml, target: /var/local/package/env.yaml }

    networks: [network]

    volumes:
      - { type: tmpfs, target: /dev/shm, tmpfs: { size: 1073741824 } }
      - { type: volume, source: ollama, target: /var/local/package/data }
      - { type: volume, source: ollama, target: /root/.ollama }

    build: .

networks:
  network: ~

volumes:
  ollama: ~
